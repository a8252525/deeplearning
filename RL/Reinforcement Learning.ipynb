{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 目標\n",
    "* 獎勵\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Goals?\n",
    "* Status\n",
    "* Rewards?\n",
    "    * at each step $t$, a reward is a number $R_t$\n",
    "* The goal is to maximizing the total rewards\n",
    "    * $ G_t = R_{t+1} + R_{t+2} + R_{t+3} + \\cdots + R_T $\n",
    "* 朝三暮四\n",
    "    * $ G_t = R_{t+1} + \\gamma R_{t+2} + \\gamma ^2 R_{t+3} + \\cdots  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 狀態\n",
    "* 策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## State Value\n",
    "\n",
    "* Policy $\\pi$\n",
    "* $S_t$ is the state at step $t$\n",
    "* $v_{\\pi}(s) = E[G_t | S_t = s] $\n",
    "* only if we knew what $v_\\pi$ is\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bellman Equation\n",
    "如果用 $a, r, s'$ 分別代表動作、獎勵、下一步的狀態。那麼\n",
    "\n",
    "$ v_\\pi (s) = \\sum_a \\pi(a|s) \\sum_{s',r} p(s', r'|s , a)(r+\\gamma v_k(s') ) $\n",
    "\n",
    "意思是 $v_\\pi (s)$   等於考慮各種可能的動作、和結果後 $r + \\gamma v(s')$  的期望值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 行動與後果\n",
    "\n",
    "從今天開始算，一生能賺到的錢 = 今天賺到的錢 + 從明天開始算，一生能賺到的錢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "有各種機率性\n",
    "\n",
    "* 同樣的動作，可能有不同的結果\n",
    "* 人在江湖，身不由己，有時無法控制動作\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Monte Carlo\n",
    "\n",
    "* 重複多次實驗，統計 $V(s)$\n",
    "* 統計的方式使用 running average    $V(s_t)  += \\alpha (G_t - V(s_t))$\n",
    "* 利用之前的統計結果 $V(s_t)  += \\alpha (r_t + \\gamma V(s_{t+1})- V(s_t))$\n",
    "* 另一種方法 `V[S] += α*(r+γ*max(V[S'|a] for all a) - V[S])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 例子\n",
    "* A -> B -> 0\n",
    "* B -> 1\n",
    "* B -> 0\n",
    "* B -> 0\n",
    "* B -> 1\n",
    "* B -> 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 探索與利用\n",
    "## Exploration and Exploitation\n",
    "## $\\epsilon$-greedy \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Temporal Difference\n",
    "\n",
    "## 當下即時更新\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Q function\n",
    "\n",
    "using $ q(s,a) $ instead of $v(s' | a)$\n",
    "\n",
    "$ V(s) = max_a Q(s, a)$\n",
    "\n",
    "更新方式為 `Q[S][a] += α*(r+γ*Q[S'].max() - Q[S][a])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sarsa\n",
    "\n",
    "更新方式為\n",
    "`Q[S][a] += α*(r+γ*Q[S'][a'] - Q[S][a]) `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Using function instead\n",
    "\n",
    "* Q(s,a) = Q[s, a]\n",
    "* Q(s) = [Q[s, a_1], Q[s, a_2], ...]\n",
    "* use SGD to update "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
