{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要先安裝 gym[atari]\n",
    "# headless 執行: xvfb-run -a jupyter notebook\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Pong-ram-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ipywidgets as W\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "def to_png(a):\n",
    "    with BytesIO() as bio:\n",
    "        Image.fromarray(a).save(bio, 'png')\n",
    "        return bio.getvalue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q learning 的骨架\n",
    "\n",
    "* 用 `compute_s(observation)` 來計算 state\n",
    "* 用 `Qupdate(s, a, v)` 來 update `Q(s,a)`\n",
    "* 用 `Qfunc(s)` 來算 `Q(s, ...)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from random import randint, random, shuffle, choice\n",
    "actions = [0,2,3]\n",
    "\n",
    "def Qlearn(test=False, screen=None, T=40):\n",
    "    observation = env.reset()\n",
    "    for i in range(50):\n",
    "        observation, reward, done, info =env.step(choice(actions))\n",
    "    s2 = compute_s(observation)\n",
    "    total_r = 0\n",
    "    for i in range(T):\n",
    "        s = s2\n",
    "        if not test and random()< ϵ:\n",
    "            a = choice(actions)\n",
    "        elif s is None:\n",
    "            a = choice(actions)\n",
    "        else:\n",
    "            a = actions[np.argmax(Qfunc(s))]\n",
    "        observation, reward, done, info = env.step(a)        \n",
    "        s2 = compute_s(observation)\n",
    "        r = reward\n",
    "        total_r+=r\n",
    "        if not test and s is not None:\n",
    "            if s2 is None:\n",
    "                r=1.\n",
    "            if r:\n",
    "                v = r\n",
    "            else:\n",
    "                v = γ*Qfunc(s2).max()\n",
    "            a = max(0, a-1)\n",
    "            Qupdate(s, a, v)\n",
    "        if screen is not None:\n",
    "            img = env.render(mode='rgb_array')\n",
    "            screen.value = to_png(img)\n",
    "            sleep(1/60)\n",
    "    return total_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最簡單的是把整個 observation 當成 state，但是很慢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LeakyReLU\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "Q = Sequential()\n",
    "Q.add(Dense(2048, input_shape=(256,)))  # 輸入是 i, j \n",
    "Q.add(LeakyReLU(0.2))\n",
    "Q.add(Dense(3)) # 因為輸出是 +-1\n",
    "Q.compile(loss='mse',optimizer=Adam(1e-4), metrics=['accuracy']) # 輸出 a\n",
    "\n",
    "def Qfunc(s):    \n",
    "    return Q.predict(s)[0]\n",
    "\n",
    "\n",
    "def Qupdate(s, a, v):    \n",
    "    Y = Q.predict(s)\n",
    "    Y[0][a] = v\n",
    "    return Q.train_on_batch(s, Y)\n",
    "\n",
    "def compute_s(observation):\n",
    "    dx = (observation[58]+128)%256-128\n",
    "    if dx>=0:\n",
    "        return None\n",
    "    ob = list(observation)\n",
    "    return np.array([ob+[(v+128)%256-128 for v in ob]], dtype='float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很久，可以小跑一下看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "screen = W.Image()\n",
    "display(screen)\n",
    "txt =W.Text()\n",
    "display(txt)\n",
    "r = 0\n",
    "γ = 1\n",
    "ϵ = 0.1\n",
    "rr= -1\n",
    "rate = []\n",
    "for j in range(101):\n",
    "    if j%100==99:\n",
    "        r=sum(Qlearn(test=True, T=40) for i in range(20))\n",
    "        print(j, r/20)\n",
    "        if r>=-2:\n",
    "            break\n",
    "    rr = rr*0.95 + 0.05*Qlearn(T=40)\n",
    "    rate.append(rr)\n",
    "    txt.value=\"j={} r={}\".format(j,rr)\n",
    "    plt.clf()\n",
    "    plt.plot(rate)\n",
    "    with BytesIO() as bio:\n",
    "        plt.savefig(bio)\n",
    "        screen.value = bio.getvalue()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之前 tabular 的 state, 用二次函數近似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LeakyReLU, LocallyConnected1D, Lambda\n",
    "from keras.initializers import Constant, RandomNormal\n",
    "from keras.activations import selu\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "Q = Sequential()\n",
    "Q.add(Dense(3, input_shape=(2,),\n",
    "            kernel_initializer=RandomNormal(stddev=0.001) ))  # 輸入是 i, j \n",
    "Q.compile(loss='mse',optimizer=SGD(1e-3)) # 輸出 a\n",
    "\n",
    "def Qfunc(s):\n",
    "    X = np.array([[s[0][0], s[0][0]**2]])\n",
    "    return Q.predict(X)[0]\n",
    "\n",
    "\n",
    "def Qupdate(s, a, v):\n",
    "    X = np.array([[s[0][0], s[0][0]**2]])\n",
    "    Y = Q.predict(X)\n",
    "    Y[0][a] = v\n",
    "    return Q.train_on_batch(X, Y)\n",
    "\n",
    "\n",
    "def compute_s(observation):\n",
    "    dx = (observation[58]+127)%256-127\n",
    "    if dx>=0:\n",
    "        return None\n",
    "    dy = (observation[56]+127)%256-127\n",
    "    x,y0 = observation[[49,54]]\n",
    "    y2 = observation[60]    \n",
    "    y = (int(y0 - (186-x)*dy/dx)-44)%(326)\n",
    "    if y>163:\n",
    "        y=326-y\n",
    "    y+=38\n",
    "    s = (y-y2)/2\n",
    "    return np.float32([[s/50]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "screen = W.Image()\n",
    "display(screen)\n",
    "txt =W.Text()\n",
    "display(txt)\n",
    "γ, ϵ, rr = 1, 3., -8\n",
    "for j in range(1001):\n",
    "    if j%100==99:\n",
    "        r=sum(Qlearn(test=True, T=400) for i in range(20))\n",
    "        print(j, r/20)\n",
    "    rr = rr*0.95 + 0.05*Qlearn(T=400)\n",
    "    txt.value=\"j={} r={} ϵ={}\".format(j,rr, ϵ)\n",
    "    plt.clf()\n",
    "    Qvalue = np.array([Qfunc(np.float32([[i/50]])) for i in range(-50,50)])\n",
    "    plt.plot(Qvalue[:,0], 'r')\n",
    "    plt.plot(Qvalue[:,1], 'g')\n",
    "    plt.plot(Qvalue[:,2], 'b')\n",
    "    with BytesIO() as bio:\n",
    "        plt.savefig(bio)\n",
    "        screen.value = bio.getvalue()\n",
    "    ϵ = max(0.1, ϵ*0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試\n",
    "screen = W.Image()\n",
    "display(screen)\n",
    "Qlearn(test=True, screen=screen, T=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用常態分佈曲線來逼近"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LeakyReLU, LocallyConnected1D, Lambda,Reshape\n",
    "from keras.initializers import Constant, RandomNormal\n",
    "from keras.activations import selu\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "import keras.backend as K\n",
    "Q = Sequential()\n",
    "Q.add(Dense(3, input_shape=(2,) , use_bias=False))  # 輸入是 i, j \n",
    "Q.add(Lambda(lambda x: K.exp(x)))\n",
    "Q.add(Reshape((3,1)))\n",
    "Q.add(LocallyConnected1D(filters=1,kernel_size=1,\n",
    "                         kernel_initializer=\"zeros\"))\n",
    "Q.add(Reshape( (3,) ))\n",
    "Q.compile(loss='mse',optimizer=SGD(1e-3)) # 輸出 a\n",
    "Q.layers[0].set_weights([np.array([[0,-1., 1.],[-3., -3., -3.]])])\n",
    "Q.layers[3].set_weights([np.array([[[.11]],[[.1]],[[.1]]]), np.array([[-0.]]*3) ])\n",
    "def Qfunc(s):\n",
    "    X = np.array([[s[0][0], s[0][0]**2]])#, s[0][0]**3, s[0][0]**4]])\n",
    "    return Q.predict(X)[0]\n",
    "\n",
    "\n",
    "def Qupdate(s, a, v):\n",
    "    X = np.array([[s[0][0], s[0][0]**2]])#, s[0][0]**3, s[0][0]**4]])\n",
    "    Y = Q.predict(X)\n",
    "    Y[0][a] = v\n",
    "    return Q.train_on_batch(X, Y)\n",
    "\n",
    "\n",
    "def compute_s(observation):\n",
    "    dx = (observation[58]+127)%256-127\n",
    "    if dx>=0:\n",
    "        return None\n",
    "    dy = (observation[56]+127)%256-127\n",
    "    x,y0 = observation[[49,54]]\n",
    "    y2 = observation[60]    \n",
    "    y = (int(y0 - (186-x)*dy/dx)-44)%(326)\n",
    "    if y>163:\n",
    "        y=326-y\n",
    "    y+=38\n",
    "    s = (y-y2)/2\n",
    "    return np.float32([[s/50]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "txt =W.Text()\n",
    "display(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "γ, ϵ, rr = 1, .1, -8\n",
    "for j in range(0, 1001):\n",
    "    if j%100==99:\n",
    "        r=sum(Qlearn(test=True, T=1400) for i in range(20))\n",
    "        print(\"{} {}\\n\".format(j, r/20))\n",
    "        if r>0:\n",
    "            break\n",
    "    rr = rr*0.95 + 0.05*Qlearn(T=1400)    \n",
    "    txt.value=\"j={} r={} ϵ={}\".format(j,rr, ϵ)\n",
    "    ax.clear()\n",
    "    Qvalue = np.array([Qfunc(np.float32([[i/50]])) for i in range(-50,50)])\n",
    "    for i, c in enumerate(\"rgb\"):\n",
    "        ax.plot(Qvalue[:,i], c)\n",
    "    fig.canvas.draw()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 增加兩個新的 action\n",
    "如果之前移動了，則這次不移動。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from random import randint, random, shuffle, choice\n",
    "actions2 = [0,2,3,4,5]\n",
    "\n",
    "def Qlearn2(test=False, screen=None, T=40):\n",
    "    observation = env.reset()\n",
    "    for i in range(50):\n",
    "        a = choice(actions2)\n",
    "        observation, reward, done, info =env.step(a)\n",
    "    s2 = compute_s(observation)\n",
    "    last_a = a\n",
    "    total_r = 0\n",
    "    for i in range(T):\n",
    "        s = s2\n",
    "        if not test and random()< ϵ:\n",
    "            a = choice(actions2)\n",
    "        elif s is None:\n",
    "            a = choice(actions2)\n",
    "        else:\n",
    "            a = actions2[np.argmax(Qfunc(s))]\n",
    "        if a>=4:\n",
    "            if last_a==a-2:\n",
    "                observation, reward, done, info = env.step(0)\n",
    "                last_a = 0\n",
    "            else:\n",
    "                observation, reward, done, info = env.step(a-2)\n",
    "                last_a = a-2\n",
    "        else:\n",
    "            observation, reward, done, info = env.step(a)\n",
    "            last_a = a\n",
    "        s2 = compute_s(observation)\n",
    "        r = reward\n",
    "        total_r+=r\n",
    "        if not test and s is not None:\n",
    "            if s2 is None:\n",
    "                r=1.\n",
    "            if r:\n",
    "                v = r\n",
    "            else:\n",
    "                v = γ*Qfunc(s2).max()\n",
    "            a = max(0, a-1)\n",
    "            Qupdate(s, a, v)\n",
    "        if screen is not None:\n",
    "            img = env.render(mode='rgb_array')\n",
    "            screen.value = to_png(img)\n",
    "            sleep(1/60)\n",
    "    return total_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型也一樣，只是多了兩個輸出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LeakyReLU, LocallyConnected1D, Lambda,Reshape\n",
    "from keras.initializers import Constant, RandomNormal\n",
    "from keras.activations import selu\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "import keras.backend as K\n",
    "Q = Sequential()\n",
    "Q.add(Dense(5, input_shape=(2,) , use_bias=False))  # 輸入是 i, j \n",
    "Q.add(Lambda(lambda x: K.exp(x)))\n",
    "Q.add(Reshape((5,1)))\n",
    "Q.add(LocallyConnected1D(filters=1,kernel_size=1,\n",
    "                         kernel_initializer=\"zeros\"))\n",
    "Q.add(Reshape( (5,) ))\n",
    "Q.compile(loss='mse',optimizer=SGD(1e-3)) # 輸出 a\n",
    "Q.layers[0].set_weights([np.array([[0,-1., 1., -1, 1],\n",
    "                                   [-12.,-3.,-3.,-6.,-6.]])])\n",
    "Q.layers[3].set_weights([np.array([[[.16]],[[.1]],[[.1]],[[.15]],[[.15]]]), np.array([[-0.]]*5) ])\n",
    "def Qfunc(s):\n",
    "    X = np.array([[s[0][0], s[0][0]**2]])\n",
    "    return Q.predict(X)[0]\n",
    "\n",
    "\n",
    "def Qupdate(s, a, v):\n",
    "    X = np.array([[s[0][0], s[0][0]**2]])\n",
    "    Y = Q.predict(X)\n",
    "    Y[0][a] = v\n",
    "    return Q.train_on_batch(X, Y)\n",
    "\n",
    "\n",
    "def compute_s(observation):\n",
    "    dx = (observation[58]+127)%256-127\n",
    "    if dx>=0:\n",
    "        return None\n",
    "    dy = (observation[56]+127)%256-127\n",
    "    x,y0 = observation[[49,54]]\n",
    "    y2 = observation[60]    \n",
    "    y = (int(y0 - (186-x)*dy/dx)-44)%(326)\n",
    "    if y>163:\n",
    "        y=326-y\n",
    "    y+=38\n",
    "    s = (y-y2)/2\n",
    "    return np.float32([[s/50]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "txt =W.Text()\n",
    "display(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "γ, ϵ, rr = 1, .1, -8\n",
    "for j in range(0, 1001):\n",
    "    if j%100==99:\n",
    "        r=sum(Qlearn2(test=True, T=1400) for i in range(20))\n",
    "        print(\"{} {}\\n\".format(j, r/20))\n",
    "        if r>0:\n",
    "            break\n",
    "    rr = rr*0.95 + 0.05*Qlearn2(T=1400)    \n",
    "    txt.value=\"j={} r={} ϵ={}\".format(j,rr, ϵ)\n",
    "    ax.clear()\n",
    "    Qvalue = np.array([Qfunc(np.float32([[i/50]])) for i in range(-50,50)])\n",
    "    for i, c in enumerate(\"rgbyk\"):\n",
    "        ax.plot(Qvalue[:,i], c)\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "Q = load_model('Qlearn2_function.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試\n",
    "screen = W.Image()\n",
    "display(screen)\n",
    "Qlearn2(test=True, screen=screen, T=1400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.save('Qlearn2_function.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
