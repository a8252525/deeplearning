{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### from __future__ import print_function\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D, Input, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 32  # orig paper trained all networks with batch_size=128\n",
    "epochs = 200\n",
    "data_augmentation = True\n",
    "num_classes = 10\n",
    "\n",
    "# Subtracting pixel mean improves accuracy\n",
    "subtract_pixel_mean = True\n",
    "\n",
    "# Model parameter\n",
    "# ----------------------------------------------------------------------------\n",
    "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
    "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
    "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
    "# ----------------------------------------------------------------------------\n",
    "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
    "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
    "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
    "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
    "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
    "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
    "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
    "# ---------------------------------------------------------------------------\n",
    "n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model version\n",
    "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
    "version = 1\n",
    "\n",
    "# Computed depth from supplied model parameter n\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2\n",
    "\n",
    "# Model name, depth and version\n",
    "model_type = 'ResNet%dv%d' % (depth, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR10 data.\n",
    "#(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "#print(type(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47500/47500 [12:27<00:00, 63.51it/s]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "DIR = './input/coic3/train'\n",
    "x,y = [],[]\n",
    "\n",
    "def make_train_label(DIR,x,y):\n",
    "    for img in tqdm(os.listdir(DIR)):\n",
    "        path = os.path.join(DIR,img)\n",
    "        pic = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "        x.append(np.array(pic))\n",
    "        #--\n",
    "        with open('./input/coic3/train_labels.csv', newline='') as csvfile:\n",
    "            rows = csv.reader(csvfile)\n",
    "            #print(dict(rows))\n",
    "            name=img[:len(img)-4]\n",
    "            y.append(dict(rows)[name])\n",
    "make_train_label(DIR,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47500, 32, 32, 3) (47500,)\n",
      "(38000,) (9500,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train=np.array(x).astype('float32')/255\n",
    "y_train=np.array(y).astype('int')\n",
    "#y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\n",
    "input_shape=x_train.shape[1:]\n",
    "print(x_train.shape,y_train.shape)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x_train,y_train,test_size=0.2,random_state=42)\n",
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input imashape dimensions.\n",
    "#input_shape = x_train.shape[1:]\n",
    "\n",
    "# Normalize data.\n",
    "#x_train = x_train.astype('float32') / 255\n",
    "#x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# If subtract pixel mean is enabled\n",
    "#if subtract_pixel_mean:\n",
    "#    x_train_mean = np.mean(x_train, axis=0)\n",
    "#    x_train -= x_train_mean\n",
    "#    x_test -= x_train_mean\n",
    "\n",
    "#print('x_train shape:', x_train.shape)\n",
    "#print(x_train.shape[0], 'train samples')\n",
    "#print(x_test.shape[0], 'test samples')\n",
    "#print('y_train shape:', y_train.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "#y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "ResNet20v1\n",
      "Using real-time data augmentation.\n",
      "Learning rate:  0.001\n",
      "Epoch 1/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 1.6766 - accuracy: 0.4431WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 132s 111ms/step - loss: 1.6765 - accuracy: 0.4430 - val_loss: 1.5415 - val_accuracy: 0.5170\n",
      "Learning rate:  0.001\n",
      "Epoch 2/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 1.3021 - accuracy: 0.5873WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 129s 109ms/step - loss: 1.3020 - accuracy: 0.5874 - val_loss: 1.2024 - val_accuracy: 0.6217\n",
      "Learning rate:  0.001\n",
      "Epoch 3/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 1.1317 - accuracy: 0.6537WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 1.1318 - accuracy: 0.6536 - val_loss: 1.1917 - val_accuracy: 0.6478\n",
      "Learning rate:  0.001\n",
      "Epoch 4/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 1.0289 - accuracy: 0.6949WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 1.0290 - accuracy: 0.6949 - val_loss: 1.0308 - val_accuracy: 0.7014\n",
      "Learning rate:  0.001\n",
      "Epoch 5/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.9600 - accuracy: 0.7225WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 128s 107ms/step - loss: 0.9599 - accuracy: 0.7225 - val_loss: 1.0713 - val_accuracy: 0.6921\n",
      "Learning rate:  0.001\n",
      "Epoch 6/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.8983 - accuracy: 0.7450WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.8983 - accuracy: 0.7450 - val_loss: 1.0693 - val_accuracy: 0.6990\n",
      "Learning rate:  0.001\n",
      "Epoch 7/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.8553 - accuracy: 0.7624WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.8553 - accuracy: 0.7624 - val_loss: 1.1271 - val_accuracy: 0.6968\n",
      "Learning rate:  0.001\n",
      "Epoch 8/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.8245 - accuracy: 0.7733WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 128s 107ms/step - loss: 0.8248 - accuracy: 0.7732 - val_loss: 0.8490 - val_accuracy: 0.7689\n",
      "Learning rate:  0.001\n",
      "Epoch 9/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.7877 - accuracy: 0.7881WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 128s 108ms/step - loss: 0.7876 - accuracy: 0.7882 - val_loss: 0.9019 - val_accuracy: 0.7453\n",
      "Learning rate:  0.001\n",
      "Epoch 10/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.7691 - accuracy: 0.7939WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 128s 107ms/step - loss: 0.7689 - accuracy: 0.7940 - val_loss: 0.9136 - val_accuracy: 0.7476\n",
      "Learning rate:  0.001\n",
      "Epoch 11/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.7438 - accuracy: 0.8049WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.7436 - accuracy: 0.8049 - val_loss: 0.8148 - val_accuracy: 0.7895\n",
      "Learning rate:  0.001\n",
      "Epoch 12/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.7310 - accuracy: 0.8101WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 128s 107ms/step - loss: 0.7309 - accuracy: 0.8102 - val_loss: 0.7569 - val_accuracy: 0.7990\n",
      "Learning rate:  0.001\n",
      "Epoch 13/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.7118 - accuracy: 0.8166WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 126s 106ms/step - loss: 0.7120 - accuracy: 0.8165 - val_loss: 0.7977 - val_accuracy: 0.7903\n",
      "Learning rate:  0.001\n",
      "Epoch 14/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.6960 - accuracy: 0.8242WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.6961 - accuracy: 0.8241 - val_loss: 0.8116 - val_accuracy: 0.7872\n",
      "Learning rate:  0.001\n",
      "Epoch 15/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.6780 - accuracy: 0.8313WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 128s 108ms/step - loss: 0.6782 - accuracy: 0.8312 - val_loss: 0.8700 - val_accuracy: 0.7744\n",
      "Learning rate:  0.001\n",
      "Epoch 16/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.6725 - accuracy: 0.8320WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.6725 - accuracy: 0.8320 - val_loss: 1.1555 - val_accuracy: 0.7145\n",
      "Learning rate:  0.001\n",
      "Epoch 17/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.6597 - accuracy: 0.8385WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 128s 108ms/step - loss: 0.6598 - accuracy: 0.8384 - val_loss: 0.8122 - val_accuracy: 0.7955\n",
      "Learning rate:  0.001\n",
      "Epoch 18/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.6543 - accuracy: 0.8394WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.6543 - accuracy: 0.8393 - val_loss: 1.2335 - val_accuracy: 0.7014\n",
      "Learning rate:  0.001\n",
      "Epoch 19/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.6386 - accuracy: 0.8474WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 128s 107ms/step - loss: 0.6391 - accuracy: 0.8472 - val_loss: 1.0229 - val_accuracy: 0.7454\n",
      "Learning rate:  0.001\n",
      "Epoch 20/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.6338 - accuracy: 0.8487WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.6336 - accuracy: 0.8488 - val_loss: 1.0176 - val_accuracy: 0.7534\n",
      "Learning rate:  0.001\n",
      "Epoch 21/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.6308 - accuracy: 0.8505WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 129s 108ms/step - loss: 0.6307 - accuracy: 0.8505 - val_loss: 0.8112 - val_accuracy: 0.8051\n",
      "Learning rate:  0.001\n",
      "Epoch 22/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.6170 - accuracy: 0.8549WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.6170 - accuracy: 0.8549 - val_loss: 1.0214 - val_accuracy: 0.7404\n",
      "Learning rate:  0.001\n",
      "Epoch 23/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.6172 - accuracy: 0.8548WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.6170 - accuracy: 0.8549 - val_loss: 0.7266 - val_accuracy: 0.8218\n",
      "Learning rate:  0.001\n",
      "Epoch 24/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.6145 - accuracy: 0.8564WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 128s 108ms/step - loss: 0.6147 - accuracy: 0.8563 - val_loss: 0.7845 - val_accuracy: 0.8047\n",
      "Learning rate:  0.001\n",
      "Epoch 25/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.6046 - accuracy: 0.8580WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 128s 108ms/step - loss: 0.6048 - accuracy: 0.8579 - val_loss: 0.8695 - val_accuracy: 0.7918\n",
      "Learning rate:  0.001\n",
      "Epoch 26/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5972 - accuracy: 0.8614WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.5971 - accuracy: 0.8614 - val_loss: 0.7711 - val_accuracy: 0.8124\n",
      "Learning rate:  0.001\n",
      "Epoch 27/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5982 - accuracy: 0.8634WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.5982 - accuracy: 0.8634 - val_loss: 0.8518 - val_accuracy: 0.7948\n",
      "Learning rate:  0.001\n",
      "Epoch 28/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5853 - accuracy: 0.8689WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.5854 - accuracy: 0.8689 - val_loss: 0.7408 - val_accuracy: 0.8210\n",
      "Learning rate:  0.001\n",
      "Epoch 29/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5865 - accuracy: 0.8680WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 128s 107ms/step - loss: 0.5864 - accuracy: 0.8681 - val_loss: 0.6631 - val_accuracy: 0.8471\n",
      "Learning rate:  0.001\n",
      "Epoch 30/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5803 - accuracy: 0.8698WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 128s 108ms/step - loss: 0.5802 - accuracy: 0.8699 - val_loss: 0.7749 - val_accuracy: 0.8187\n",
      "Learning rate:  0.001\n",
      "Epoch 31/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5813 - accuracy: 0.8696WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.5815 - accuracy: 0.8696 - val_loss: 0.7593 - val_accuracy: 0.8311\n",
      "Learning rate:  0.001\n",
      "Epoch 32/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5785 - accuracy: 0.8716WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.5784 - accuracy: 0.8717 - val_loss: 0.7938 - val_accuracy: 0.8152\n",
      "Learning rate:  0.001\n",
      "Epoch 33/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5703 - accuracy: 0.8747WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.5701 - accuracy: 0.8747 - val_loss: 0.7181 - val_accuracy: 0.8359\n",
      "Learning rate:  0.001\n",
      "Epoch 34/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5693 - accuracy: 0.8751WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.5694 - accuracy: 0.8751 - val_loss: 0.7963 - val_accuracy: 0.8207\n",
      "Learning rate:  0.001\n",
      "Epoch 35/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5703 - accuracy: 0.8740WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 128s 108ms/step - loss: 0.5704 - accuracy: 0.8740 - val_loss: 0.6687 - val_accuracy: 0.8442\n",
      "Learning rate:  0.001\n",
      "Epoch 36/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5573 - accuracy: 0.8793WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 128s 108ms/step - loss: 0.5573 - accuracy: 0.8793 - val_loss: 0.7583 - val_accuracy: 0.8191\n",
      "Learning rate:  0.001\n",
      "Epoch 37/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5604 - accuracy: 0.8780WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.5603 - accuracy: 0.8781 - val_loss: 0.7466 - val_accuracy: 0.8153\n",
      "Learning rate:  0.001\n",
      "Epoch 38/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5589 - accuracy: 0.8798WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.5589 - accuracy: 0.8797 - val_loss: 0.7480 - val_accuracy: 0.8242\n",
      "Learning rate:  0.001\n",
      "Epoch 39/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5541 - accuracy: 0.8805WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 128s 107ms/step - loss: 0.5540 - accuracy: 0.8806 - val_loss: 0.7952 - val_accuracy: 0.8140\n",
      "Learning rate:  0.001\n",
      "Epoch 40/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5496 - accuracy: 0.8830WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.5498 - accuracy: 0.8829 - val_loss: 0.6906 - val_accuracy: 0.8449\n",
      "Learning rate:  0.001\n",
      "Epoch 41/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5530 - accuracy: 0.8811WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.5529 - accuracy: 0.8811 - val_loss: 0.8119 - val_accuracy: 0.8070\n",
      "Learning rate:  0.001\n",
      "Epoch 42/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5517 - accuracy: 0.8840WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 128s 108ms/step - loss: 0.5516 - accuracy: 0.8840 - val_loss: 0.9238 - val_accuracy: 0.7834\n",
      "Learning rate:  0.001\n",
      "Epoch 43/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5459 - accuracy: 0.8852WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.5457 - accuracy: 0.8853 - val_loss: 0.7334 - val_accuracy: 0.8338\n",
      "Learning rate:  0.001\n",
      "Epoch 44/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5423 - accuracy: 0.8829WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.5422 - accuracy: 0.8829 - val_loss: 0.6974 - val_accuracy: 0.8349\n",
      "Learning rate:  0.001\n",
      "Epoch 45/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5427 - accuracy: 0.8876WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 128s 108ms/step - loss: 0.5426 - accuracy: 0.8877 - val_loss: 0.8591 - val_accuracy: 0.8019\n",
      "Learning rate:  0.001\n",
      "Epoch 46/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5406 - accuracy: 0.8845WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.5404 - accuracy: 0.8846 - val_loss: 0.7435 - val_accuracy: 0.8345\n",
      "Learning rate:  0.001\n",
      "Epoch 47/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5357 - accuracy: 0.8882WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.5361 - accuracy: 0.8882 - val_loss: 0.7056 - val_accuracy: 0.8433\n",
      "Learning rate:  0.001\n",
      "Epoch 48/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5375 - accuracy: 0.8869WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 128s 108ms/step - loss: 0.5376 - accuracy: 0.8868 - val_loss: 0.7464 - val_accuracy: 0.8269\n",
      "Learning rate:  0.001\n",
      "Epoch 49/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5373 - accuracy: 0.8892WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 127s 107ms/step - loss: 0.5373 - accuracy: 0.8892 - val_loss: 0.6898 - val_accuracy: 0.8393\n",
      "Learning rate:  0.001\n",
      "Epoch 50/200\n",
      "1187/1188 [============================>.] - ETA: 0s - loss: 0.5351 - accuracy: 0.8885WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence` class.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1188/1188 [==============================] - 128s 108ms/step - loss: 0.5350 - accuracy: 0.8885 - val_loss: 0.7732 - val_accuracy: 0.8110\n",
      "Learning rate:  0.001\n",
      "Epoch 51/200\n",
      " 484/1188 [===========>..................] - ETA: 1:07 - loss: 0.5286 - accuracy: 0.8897"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Keras_worker_ForkPoolWorker-400:\n",
      "Process Keras_worker_ForkPoolWorker-397:\n",
      "Process Keras_worker_ForkPoolWorker-398:\n",
      "Process Keras_worker_ForkPoolWorker-399:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/data_utils.py\", line 571, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n",
      "    return self._get_batches_of_transformed_samples(index_array)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/keras_preprocessing/image/numpy_array_iterator.py\", line 153, in _get_batches_of_transformed_samples\n",
      "    x.astype(self.dtype), params)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/keras_preprocessing/image/image_data_generator.py\", line 870, in apply_transform\n",
      "    order=self.interpolation_order)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/keras_preprocessing/image/affine_transformations.py\", line 333, in apply_affine_transform\n",
      "    cval=cval) for x_channel in x]\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/keras_preprocessing/image/affine_transformations.py\", line 333, in <listcomp>\n",
      "    cval=cval) for x_channel in x]\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\", line 480, in affine_transform\n",
      "    output, order, mode, cval, None, None)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d44278296918>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    265\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m                        use_multiprocessing=True )\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;31m# Score trained model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    250\u001b[0m               \u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m               \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m               training=training))\n\u001b[0m\u001b[1;32m    253\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         raise ValueError('The model cannot be run '\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fused_batch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvirtual_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;31m# Currently never reaches here since fused_batch_norm does not support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_update\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariance_update\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_update\u001b[0;34m(self, updates, inputs)\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m             \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1266\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36mvariance_update\u001b[0;34m()\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m           return self._assign_moving_average(self.moving_variance, variance,\n\u001b[0;32m--> 554\u001b[0;31m                                              momentum, inputs_size)\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_update\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36m_assign_moving_average\u001b[0;34m(self, variable, value, momentum, inputs_size)\u001b[0m\n\u001b[1;32m    476\u001b[0m           update_delta = array_ops.where(inputs_size > 0, update_delta,\n\u001b[1;32m    477\u001b[0m                                          K.zeros_like(update_delta))\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_assign_new_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/state_ops.py\u001b[0m in \u001b[0;36massign_sub\u001b[0;34m(ref, value, use_locking, name)\u001b[0m\n\u001b[1;32m    162\u001b[0m     return gen_state_ops.assign_sub(\n\u001b[1;32m    163\u001b[0m         ref, value, use_locking=use_locking, name=name)\n\u001b[0;32m--> 164\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign_sub\u001b[0;34m(self, delta, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    757\u001b[0m           name=name)\n\u001b[1;32m    758\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_sub_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0massign_sub_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_lazy_read\u001b[0;34m(self, op)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0min_graph_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_graph_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mdeleter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_deleter\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_graph_mode\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m         parent_op=op, unique_id=self._unique_id)\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, handle, dtype, shape, in_graph_mode, deleter, parent_op, unique_id)\u001b[0m\n\u001b[1;32m   1805\u001b[0m   def __init__(self, handle, dtype, shape, in_graph_mode, deleter,\n\u001b[1;32m   1806\u001b[0m                parent_op, unique_id):\n\u001b[0;32m-> 1807\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m       \u001b[0mhandle_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def resnet_v1(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 1 Model builder [a]\n",
    "\n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    Last ReLU is after the shortcut connection.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filters is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same number of filters.\n",
    "    Features maps sizes:\n",
    "    stage 0: 32x32, 16\n",
    "    stage 1: 16x16, 32\n",
    "    stage 2:  8x8,  64\n",
    "    The Number of parameters is approx the same as Table 6 of [a]:\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # Start model definition.\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    # Instantiate the stack of residual units\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = tensorflow.keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_v2(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filter maps is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same filter map sizes.\n",
    "    Features maps sizes:\n",
    "    conv1  : 32x32,  16\n",
    "    stage 0: 32x32,  64\n",
    "    stage 1: 16x16, 128\n",
    "    stage 2:  8x8,  256\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate the stack of residual units\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:  # first layer and first stage\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  # first layer but not first stage\n",
    "                    strides = 2    # downsample\n",
    "\n",
    "            # bottleneck residual unit\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = tensorflow.keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "if version == 2:\n",
    "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
    "else:\n",
    "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(learning_rate=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "#model.summary()\n",
    "print(model_type)\n",
    "\n",
    "# Prepare model model saving directory.\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "# Run training, with or without data augmentation.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # epsilon for ZCA whitening\n",
    "        zca_epsilon=1e-06,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # set range for random shear\n",
    "        shear_range=0.,\n",
    "        # set range for random zoom\n",
    "        zoom_range=0.,\n",
    "        # set range for random channel shifts\n",
    "        channel_shift_range=0.,\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        # value used for fill_mode = \"constant\"\n",
    "        cval=0.,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False,\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=epochs, verbose=1, workers=4,\n",
    "                        callbacks=callbacks,\n",
    "                       use_multiprocessing=True )\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = './input/coic3/finaltest'\n",
    "\n",
    "tmp1 = []\n",
    "\n",
    "#def make_test(DIR,x):\n",
    "#    for img in tqdm(os.listdir(DIR)):\n",
    "#        path = os.path.join(DIR,img)\n",
    "#        pic = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "#        x.append(np.array(pic))\n",
    "#make_test(DIR,tmp1)\n",
    "for i in range(1,2501):\n",
    "    path='./input/coic3/finaltest/test ({}).png'.format(i)\n",
    "    pic=cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "    tmp1.append(np.array(pic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test (1207).png', 'test (1438).png', 'test (1888).png', 'test (1934).png', 'test (2238).png']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(DIR) [0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "x_finaltest=np.array(tmp1).astype('float32')/255\n",
    "print(x_finaltest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_ans = model.predict(x_finaltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.0064214e-04 1.4541136e-07 9.6614623e-01 ... 1.4700645e-04\n",
      "  4.2625126e-07 2.2551089e-07]\n",
      " [3.8702881e-05 1.2374438e-04 1.2597941e-06 ... 9.0635140e-06\n",
      "  3.0759026e-07 9.9977404e-01]\n",
      " [7.1896958e-01 1.3126686e-01 2.1551435e-03 ... 7.0622722e-03\n",
      "  2.7920471e-03 4.2863194e-02]\n",
      " ...\n",
      " [2.3215662e-01 8.5865483e-03 2.9215624e-04 ... 2.3887092e-03\n",
      "  1.9886075e-02 7.3104960e-01]\n",
      " [1.6475153e-10 9.9999630e-01 1.6235112e-10 ... 1.8359129e-12\n",
      "  1.2730927e-08 3.6833878e-06]\n",
      " [9.1837317e-01 5.5312488e-02 1.5871937e-04 ... 1.2033052e-04\n",
      "  1.7711864e-03 8.8775381e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(before_ans)\n",
    "ans=[]\n",
    "for i,a in enumerate(before_ans):\n",
    "    m=[i+1,a.argmax()]\n",
    "    ans.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2], [2, 9], [3, 0], [4, 4], [5, 9], [6, 5], [7, 8], [8, 5], [9, 5], [10, 3], [11, 4], [12, 9], [13, 9], [14, 6], [15, 2], [16, 9], [17, 7], [18, 4], [19, 3], [20, 1], [21, 0], [22, 1], [23, 7], [24, 2], [25, 5], [26, 0], [27, 6], [28, 8], [29, 2], [30, 1], [31, 4], [32, 8], [33, 1], [34, 2], [35, 3], [36, 1], [37, 6], [38, 0], [39, 4], [40, 3], [41, 1], [42, 3], [43, 1], [44, 8], [45, 5], [46, 6], [47, 6], [48, 3], [49, 2], [50, 1], [51, 0], [52, 7], [53, 6], [54, 3], [55, 3], [56, 5], [57, 7], [58, 0], [59, 7], [60, 7], [61, 0], [62, 8], [63, 8], [64, 2], [65, 1], [66, 2], [67, 1], [68, 6], [69, 1], [70, 9], [71, 4], [72, 4], [73, 7], [74, 4], [75, 9], [76, 7], [77, 4], [78, 9], [79, 6], [80, 0], [81, 6], [82, 0], [83, 1], [84, 9], [85, 2], [86, 0], [87, 7], [88, 2], [89, 1], [90, 2], [91, 7], [92, 3], [93, 9], [94, 2], [95, 2], [96, 6], [97, 8], [98, 8], [99, 7], [100, 0], [101, 6], [102, 2], [103, 5], [104, 9], [105, 7], [106, 4], [107, 1], [108, 7], [109, 8], [110, 8], [111, 8], [112, 4], [113, 8], [114, 4], [115, 1], [116, 8], [117, 1], [118, 0], [119, 1], [120, 9], [121, 5], [122, 5], [123, 4], [124, 4], [125, 2], [126, 5], [127, 4], [128, 6], [129, 8], [130, 5], [131, 4], [132, 4], [133, 2], [134, 1], [135, 6], [136, 0], [137, 9], [138, 9], [139, 7], [140, 1], [141, 6], [142, 9], [143, 1], [144, 3], [145, 2], [146, 0], [147, 8], [148, 5], [149, 9], [150, 6], [151, 6], [152, 0], [153, 8], [154, 6], [155, 3], [156, 8], [157, 9], [158, 7], [159, 8], [160, 2], [161, 9], [162, 2], [163, 5], [164, 9], [165, 4], [166, 7], [167, 3], [168, 5], [169, 3], [170, 8], [171, 1], [172, 6], [173, 5], [174, 2], [175, 4], [176, 2], [177, 0], [178, 0], [179, 3], [180, 8], [181, 1], [182, 3], [183, 7], [184, 3], [185, 3], [186, 0], [187, 1], [188, 9], [189, 5], [190, 0], [191, 9], [192, 0], [193, 1], [194, 0], [195, 0], [196, 2], [197, 3], [198, 9], [199, 2], [200, 9], [201, 9], [202, 1], [203, 3], [204, 1], [205, 1], [206, 9], [207, 1], [208, 6], [209, 8], [210, 9], [211, 0], [212, 0], [213, 6], [214, 8], [215, 5], [216, 9], [217, 4], [218, 6], [219, 2], [220, 2], [221, 5], [222, 3], [223, 3], [224, 8], [225, 2], [226, 2], [227, 0], [228, 2], [229, 2], [230, 5], [231, 2], [232, 7], [233, 2], [234, 0], [235, 6], [236, 4], [237, 3], [238, 3], [239, 4], [240, 5], [241, 0], [242, 0], [243, 2], [244, 9], [245, 8], [246, 1], [247, 8], [248, 7], [249, 7], [250, 1], [251, 2], [252, 1], [253, 6], [254, 5], [255, 0], [256, 9], [257, 3], [258, 5], [259, 8], [260, 2], [261, 6], [262, 1], [263, 3], [264, 0], [265, 2], [266, 9], [267, 0], [268, 9], [269, 3], [270, 5], [271, 8], [272, 0], [273, 1], [274, 5], [275, 1], [276, 3], [277, 8], [278, 7], [279, 3], [280, 1], [281, 8], [282, 3], [283, 0], [284, 5], [285, 8], [286, 9], [287, 5], [288, 9], [289, 3], [290, 9], [291, 6], [292, 8], [293, 4], [294, 8], [295, 7], [296, 4], [297, 4], [298, 6], [299, 4], [300, 9], [301, 2], [302, 5], [303, 8], [304, 2], [305, 3], [306, 0], [307, 8], [308, 8], [309, 2], [310, 6], [311, 5], [312, 6], [313, 3], [314, 4], [315, 8], [316, 5], [317, 2], [318, 7], [319, 8], [320, 6], [321, 4], [322, 6], [323, 8], [324, 7], [325, 1], [326, 8], [327, 2], [328, 8], [329, 7], [330, 8], [331, 3], [332, 9], [333, 8], [334, 4], [335, 0], [336, 7], [337, 1], [338, 4], [339, 3], [340, 1], [341, 3], [342, 9], [343, 8], [344, 8], [345, 7], [346, 1], [347, 2], [348, 5], [349, 6], [350, 4], [351, 2], [352, 6], [353, 0], [354, 2], [355, 8], [356, 4], [357, 7], [358, 4], [359, 6], [360, 4], [361, 8], [362, 2], [363, 3], [364, 9], [365, 7], [366, 0], [367, 3], [368, 4], [369, 2], [370, 4], [371, 6], [372, 8], [373, 2], [374, 6], [375, 2], [376, 9], [377, 0], [378, 8], [379, 6], [380, 8], [381, 2], [382, 8], [383, 1], [384, 4], [385, 5], [386, 2], [387, 8], [388, 4], [389, 4], [390, 0], [391, 7], [392, 4], [393, 6], [394, 5], [395, 8], [396, 9], [397, 9], [398, 3], [399, 7], [400, 5], [401, 1], [402, 3], [403, 3], [404, 1], [405, 2], [406, 5], [407, 0], [408, 4], [409, 2], [410, 4], [411, 6], [412, 5], [413, 0], [414, 5], [415, 6], [416, 3], [417, 0], [418, 4], [419, 3], [420, 5], [421, 5], [422, 4], [423, 4], [424, 4], [425, 7], [426, 0], [427, 1], [428, 9], [429, 4], [430, 5], [431, 1], [432, 0], [433, 2], [434, 3], [435, 6], [436, 2], [437, 5], [438, 6], [439, 5], [440, 1], [441, 2], [442, 7], [443, 5], [444, 0], [445, 9], [446, 8], [447, 0], [448, 8], [449, 2], [450, 5], [451, 3], [452, 4], [453, 5], [454, 6], [455, 5], [456, 1], [457, 2], [458, 2], [459, 2], [460, 9], [461, 8], [462, 6], [463, 6], [464, 3], [465, 5], [466, 6], [467, 0], [468, 0], [469, 1], [470, 0], [471, 6], [472, 8], [473, 4], [474, 5], [475, 8], [476, 4], [477, 6], [478, 5], [479, 8], [480, 6], [481, 0], [482, 0], [483, 3], [484, 7], [485, 6], [486, 9], [487, 8], [488, 1], [489, 5], [490, 1], [491, 8], [492, 1], [493, 8], [494, 8], [495, 0], [496, 3], [497, 7], [498, 6], [499, 3], [500, 8], [501, 1], [502, 0], [503, 6], [504, 1], [505, 5], [506, 3], [507, 5], [508, 3], [509, 4], [510, 0], [511, 5], [512, 5], [513, 2], [514, 0], [515, 2], [516, 2], [517, 4], [518, 9], [519, 4], [520, 2], [521, 7], [522, 1], [523, 6], [524, 4], [525, 3], [526, 5], [527, 0], [528, 2], [529, 3], [530, 7], [531, 1], [532, 9], [533, 0], [534, 9], [535, 1], [536, 7], [537, 1], [538, 3], [539, 4], [540, 2], [541, 9], [542, 5], [543, 8], [544, 6], [545, 8], [546, 3], [547, 4], [548, 6], [549, 5], [550, 6], [551, 5], [552, 9], [553, 3], [554, 1], [555, 0], [556, 7], [557, 5], [558, 6], [559, 3], [560, 2], [561, 7], [562, 9], [563, 3], [564, 3], [565, 0], [566, 6], [567, 7], [568, 6], [569, 4], [570, 0], [571, 6], [572, 0], [573, 6], [574, 5], [575, 0], [576, 1], [577, 8], [578, 5], [579, 1], [580, 6], [581, 4], [582, 8], [583, 2], [584, 9], [585, 9], [586, 3], [587, 1], [588, 4], [589, 4], [590, 2], [591, 2], [592, 4], [593, 2], [594, 2], [595, 0], [596, 2], [597, 0], [598, 3], [599, 9], [600, 7], [601, 0], [602, 2], [603, 2], [604, 6], [605, 7], [606, 2], [607, 9], [608, 8], [609, 0], [610, 0], [611, 3], [612, 7], [613, 3], [614, 1], [615, 5], [616, 1], [617, 9], [618, 2], [619, 3], [620, 0], [621, 8], [622, 9], [623, 1], [624, 9], [625, 8], [626, 8], [627, 9], [628, 8], [629, 1], [630, 9], [631, 0], [632, 3], [633, 3], [634, 8], [635, 6], [636, 5], [637, 0], [638, 3], [639, 1], [640, 6], [641, 9], [642, 1], [643, 6], [644, 4], [645, 5], [646, 0], [647, 2], [648, 0], [649, 0], [650, 7], [651, 9], [652, 0], [653, 9], [654, 7], [655, 2], [656, 5], [657, 8], [658, 3], [659, 8], [660, 3], [661, 6], [662, 3], [663, 2], [664, 4], [665, 8], [666, 9], [667, 7], [668, 6], [669, 8], [670, 2], [671, 3], [672, 9], [673, 4], [674, 1], [675, 0], [676, 8], [677, 6], [678, 7], [679, 9], [680, 2], [681, 7], [682, 5], [683, 1], [684, 0], [685, 6], [686, 1], [687, 3], [688, 0], [689, 6], [690, 5], [691, 6], [692, 4], [693, 9], [694, 5], [695, 2], [696, 4], [697, 9], [698, 0], [699, 7], [700, 5], [701, 3], [702, 6], [703, 2], [704, 6], [705, 7], [706, 2], [707, 6], [708, 2], [709, 5], [710, 0], [711, 9], [712, 0], [713, 0], [714, 8], [715, 6], [716, 1], [717, 4], [718, 0], [719, 6], [720, 7], [721, 0], [722, 4], [723, 2], [724, 4], [725, 1], [726, 8], [727, 0], [728, 8], [729, 4], [730, 6], [731, 6], [732, 0], [733, 0], [734, 3], [735, 1], [736, 4], [737, 7], [738, 7], [739, 9], [740, 0], [741, 5], [742, 6], [743, 2], [744, 7], [745, 2], [746, 5], [747, 0], [748, 8], [749, 3], [750, 8], [751, 6], [752, 4], [753, 0], [754, 8], [755, 0], [756, 7], [757, 7], [758, 0], [759, 7], [760, 2], [761, 9], [762, 2], [763, 3], [764, 1], [765, 1], [766, 7], [767, 0], [768, 6], [769, 9], [770, 1], [771, 2], [772, 8], [773, 7], [774, 8], [775, 5], [776, 1], [777, 9], [778, 6], [779, 9], [780, 1], [781, 0], [782, 8], [783, 2], [784, 7], [785, 0], [786, 3], [787, 8], [788, 2], [789, 2], [790, 0], [791, 5], [792, 0], [793, 9], [794, 1], [795, 1], [796, 0], [797, 3], [798, 8], [799, 4], [800, 8], [801, 2], [802, 5], [803, 5], [804, 7], [805, 7], [806, 4], [807, 3], [808, 7], [809, 9], [810, 4], [811, 1], [812, 0], [813, 1], [814, 9], [815, 2], [816, 3], [817, 3], [818, 0], [819, 3], [820, 5], [821, 8], [822, 6], [823, 1], [824, 2], [825, 0], [826, 6], [827, 3], [828, 0], [829, 3], [830, 9], [831, 5], [832, 3], [833, 9], [834, 8], [835, 4], [836, 8], [837, 8], [838, 6], [839, 4], [840, 9], [841, 9], [842, 5], [843, 8], [844, 7], [845, 2], [846, 9], [847, 3], [848, 0], [849, 2], [850, 7], [851, 0], [852, 4], [853, 6], [854, 9], [855, 2], [856, 0], [857, 3], [858, 7], [859, 1], [860, 0], [861, 4], [862, 6], [863, 5], [864, 0], [865, 2], [866, 2], [867, 2], [868, 3], [869, 3], [870, 6], [871, 2], [872, 0], [873, 8], [874, 6], [875, 8], [876, 1], [877, 6], [878, 5], [879, 0], [880, 8], [881, 8], [882, 3], [883, 7], [884, 5], [885, 2], [886, 9], [887, 7], [888, 9], [889, 2], [890, 0], [891, 3], [892, 2], [893, 2], [894, 8], [895, 4], [896, 5], [897, 6], [898, 5], [899, 5], [900, 4], [901, 2], [902, 6], [903, 3], [904, 5], [905, 2], [906, 9], [907, 6], [908, 4], [909, 9], [910, 3], [911, 3], [912, 2], [913, 5], [914, 4], [915, 2], [916, 0], [917, 0], [918, 4], [919, 2], [920, 0], [921, 7], [922, 5], [923, 5], [924, 7], [925, 0], [926, 2], [927, 0], [928, 2], [929, 0], [930, 4], [931, 0], [932, 0], [933, 8], [934, 4], [935, 9], [936, 9], [937, 7], [938, 5], [939, 7], [940, 9], [941, 8], [942, 1], [943, 9], [944, 2], [945, 5], [946, 8], [947, 6], [948, 4], [949, 6], [950, 9], [951, 9], [952, 9], [953, 3], [954, 7], [955, 5], [956, 9], [957, 7], [958, 8], [959, 2], [960, 8], [961, 6], [962, 9], [963, 8], [964, 6], [965, 7], [966, 1], [967, 7], [968, 7], [969, 9], [970, 8], [971, 0], [972, 0], [973, 2], [974, 6], [975, 5], [976, 8], [977, 0], [978, 5], [979, 2], [980, 3], [981, 2], [982, 8], [983, 2], [984, 6], [985, 4], [986, 0], [987, 7], [988, 7], [989, 4], [990, 0], [991, 7], [992, 8], [993, 0], [994, 2], [995, 3], [996, 5], [997, 1], [998, 6], [999, 7], [1000, 2], [1001, 8], [1002, 2], [1003, 4], [1004, 9], [1005, 2], [1006, 4], [1007, 5], [1008, 3], [1009, 0], [1010, 9], [1011, 5], [1012, 6], [1013, 5], [1014, 4], [1015, 0], [1016, 1], [1017, 0], [1018, 3], [1019, 2], [1020, 6], [1021, 0], [1022, 4], [1023, 2], [1024, 7], [1025, 3], [1026, 6], [1027, 6], [1028, 7], [1029, 9], [1030, 4], [1031, 2], [1032, 5], [1033, 6], [1034, 4], [1035, 8], [1036, 6], [1037, 3], [1038, 3], [1039, 4], [1040, 1], [1041, 3], [1042, 8], [1043, 6], [1044, 3], [1045, 9], [1046, 6], [1047, 0], [1048, 2], [1049, 7], [1050, 4], [1051, 8], [1052, 2], [1053, 8], [1054, 2], [1055, 0], [1056, 5], [1057, 0], [1058, 0], [1059, 8], [1060, 9], [1061, 0], [1062, 0], [1063, 8], [1064, 4], [1065, 1], [1066, 6], [1067, 5], [1068, 7], [1069, 9], [1070, 8], [1071, 1], [1072, 3], [1073, 3], [1074, 5], [1075, 1], [1076, 6], [1077, 7], [1078, 1], [1079, 7], [1080, 7], [1081, 0], [1082, 7], [1083, 6], [1084, 8], [1085, 1], [1086, 3], [1087, 7], [1088, 0], [1089, 4], [1090, 4], [1091, 9], [1092, 4], [1093, 4], [1094, 6], [1095, 2], [1096, 1], [1097, 7], [1098, 8], [1099, 2], [1100, 2], [1101, 6], [1102, 3], [1103, 8], [1104, 9], [1105, 8], [1106, 4], [1107, 9], [1108, 6], [1109, 2], [1110, 3], [1111, 1], [1112, 0], [1113, 1], [1114, 4], [1115, 3], [1116, 9], [1117, 4], [1118, 1], [1119, 0], [1120, 6], [1121, 7], [1122, 4], [1123, 9], [1124, 9], [1125, 5], [1126, 5], [1127, 9], [1128, 6], [1129, 6], [1130, 5], [1131, 7], [1132, 1], [1133, 5], [1134, 9], [1135, 0], [1136, 0], [1137, 1], [1138, 4], [1139, 0], [1140, 1], [1141, 1], [1142, 8], [1143, 7], [1144, 0], [1145, 1], [1146, 5], [1147, 9], [1148, 8], [1149, 9], [1150, 7], [1151, 6], [1152, 2], [1153, 9], [1154, 0], [1155, 9], [1156, 8], [1157, 1], [1158, 3], [1159, 6], [1160, 6], [1161, 5], [1162, 3], [1163, 9], [1164, 0], [1165, 6], [1166, 6], [1167, 5], [1168, 1], [1169, 8], [1170, 1], [1171, 8], [1172, 0], [1173, 9], [1174, 5], [1175, 5], [1176, 1], [1177, 2], [1178, 0], [1179, 8], [1180, 7], [1181, 9], [1182, 1], [1183, 9], [1184, 5], [1185, 4], [1186, 5], [1187, 3], [1188, 0], [1189, 7], [1190, 4], [1191, 8], [1192, 0], [1193, 2], [1194, 3], [1195, 2], [1196, 7], [1197, 1], [1198, 7], [1199, 8], [1200, 2], [1201, 8], [1202, 3], [1203, 2], [1204, 2], [1205, 5], [1206, 9], [1207, 1], [1208, 2], [1209, 5], [1210, 1], [1211, 6], [1212, 3], [1213, 2], [1214, 1], [1215, 7], [1216, 2], [1217, 4], [1218, 7], [1219, 9], [1220, 3], [1221, 7], [1222, 6], [1223, 3], [1224, 6], [1225, 5], [1226, 8], [1227, 8], [1228, 7], [1229, 1], [1230, 0], [1231, 2], [1232, 4], [1233, 4], [1234, 2], [1235, 9], [1236, 2], [1237, 4], [1238, 8], [1239, 4], [1240, 2], [1241, 1], [1242, 8], [1243, 3], [1244, 0], [1245, 8], [1246, 0], [1247, 1], [1248, 6], [1249, 0], [1250, 1], [1251, 5], [1252, 9], [1253, 8], [1254, 6], [1255, 5], [1256, 8], [1257, 8], [1258, 8], [1259, 3], [1260, 0], [1261, 4], [1262, 3], [1263, 4], [1264, 4], [1265, 2], [1266, 6], [1267, 9], [1268, 3], [1269, 2], [1270, 1], [1271, 6], [1272, 6], [1273, 3], [1274, 7], [1275, 8], [1276, 5], [1277, 3], [1278, 0], [1279, 0], [1280, 2], [1281, 2], [1282, 4], [1283, 0], [1284, 2], [1285, 2], [1286, 5], [1287, 2], [1288, 4], [1289, 0], [1290, 6], [1291, 2], [1292, 1], [1293, 0], [1294, 8], [1295, 8], [1296, 6], [1297, 2], [1298, 5], [1299, 3], [1300, 1], [1301, 0], [1302, 4], [1303, 6], [1304, 7], [1305, 6], [1306, 8], [1307, 1], [1308, 4], [1309, 3], [1310, 9], [1311, 9], [1312, 7], [1313, 4], [1314, 7], [1315, 3], [1316, 7], [1317, 1], [1318, 5], [1319, 1], [1320, 6], [1321, 1], [1322, 8], [1323, 5], [1324, 7], [1325, 4], [1326, 4], [1327, 7], [1328, 9], [1329, 5], [1330, 7], [1331, 3], [1332, 2], [1333, 5], [1334, 2], [1335, 3], [1336, 2], [1337, 8], [1338, 7], [1339, 8], [1340, 9], [1341, 1], [1342, 6], [1343, 0], [1344, 5], [1345, 0], [1346, 1], [1347, 4], [1348, 0], [1349, 7], [1350, 5], [1351, 0], [1352, 0], [1353, 0], [1354, 7], [1355, 6], [1356, 6], [1357, 0], [1358, 2], [1359, 7], [1360, 0], [1361, 4], [1362, 0], [1363, 4], [1364, 9], [1365, 8], [1366, 7], [1367, 6], [1368, 3], [1369, 9], [1370, 0], [1371, 2], [1372, 8], [1373, 8], [1374, 2], [1375, 8], [1376, 4], [1377, 4], [1378, 8], [1379, 6], [1380, 4], [1381, 3], [1382, 4], [1383, 3], [1384, 4], [1385, 4], [1386, 2], [1387, 6], [1388, 9], [1389, 6], [1390, 4], [1391, 5], [1392, 0], [1393, 4], [1394, 2], [1395, 2], [1396, 6], [1397, 7], [1398, 6], [1399, 1], [1400, 1], [1401, 5], [1402, 1], [1403, 0], [1404, 7], [1405, 6], [1406, 8], [1407, 2], [1408, 3], [1409, 0], [1410, 5], [1411, 5], [1412, 8], [1413, 3], [1414, 6], [1415, 3], [1416, 1], [1417, 9], [1418, 1], [1419, 7], [1420, 9], [1421, 0], [1422, 9], [1423, 2], [1424, 7], [1425, 0], [1426, 6], [1427, 0], [1428, 7], [1429, 3], [1430, 6], [1431, 0], [1432, 5], [1433, 6], [1434, 3], [1435, 5], [1436, 5], [1437, 8], [1438, 2], [1439, 7], [1440, 0], [1441, 6], [1442, 6], [1443, 6], [1444, 8], [1445, 2], [1446, 4], [1447, 3], [1448, 6], [1449, 7], [1450, 9], [1451, 4], [1452, 4], [1453, 3], [1454, 1], [1455, 1], [1456, 4], [1457, 6], [1458, 3], [1459, 0], [1460, 8], [1461, 7], [1462, 4], [1463, 1], [1464, 9], [1465, 8], [1466, 8], [1467, 3], [1468, 5], [1469, 2], [1470, 0], [1471, 1], [1472, 0], [1473, 1], [1474, 0], [1475, 6], [1476, 1], [1477, 3], [1478, 6], [1479, 8], [1480, 0], [1481, 5], [1482, 6], [1483, 9], [1484, 6], [1485, 8], [1486, 4], [1487, 0], [1488, 9], [1489, 2], [1490, 2], [1491, 8], [1492, 5], [1493, 2], [1494, 3], [1495, 2], [1496, 1], [1497, 9], [1498, 4], [1499, 9], [1500, 3], [1501, 8], [1502, 9], [1503, 2], [1504, 9], [1505, 9], [1506, 3], [1507, 0], [1508, 8], [1509, 2], [1510, 4], [1511, 7], [1512, 8], [1513, 9], [1514, 4], [1515, 7], [1516, 3], [1517, 2], [1518, 5], [1519, 0], [1520, 7], [1521, 2], [1522, 1], [1523, 1], [1524, 4], [1525, 4], [1526, 8], [1527, 9], [1528, 4], [1529, 6], [1530, 9], [1531, 4], [1532, 9], [1533, 2], [1534, 5], [1535, 2], [1536, 9], [1537, 9], [1538, 7], [1539, 7], [1540, 6], [1541, 1], [1542, 6], [1543, 8], [1544, 8], [1545, 3], [1546, 1], [1547, 6], [1548, 7], [1549, 7], [1550, 2], [1551, 0], [1552, 2], [1553, 5], [1554, 2], [1555, 2], [1556, 4], [1557, 6], [1558, 9], [1559, 7], [1560, 6], [1561, 1], [1562, 6], [1563, 6], [1564, 7], [1565, 9], [1566, 9], [1567, 1], [1568, 0], [1569, 2], [1570, 2], [1571, 5], [1572, 7], [1573, 9], [1574, 9], [1575, 9], [1576, 1], [1577, 6], [1578, 6], [1579, 3], [1580, 3], [1581, 1], [1582, 3], [1583, 3], [1584, 2], [1585, 1], [1586, 1], [1587, 9], [1588, 9], [1589, 8], [1590, 3], [1591, 8], [1592, 0], [1593, 0], [1594, 0], [1595, 6], [1596, 6], [1597, 1], [1598, 4], [1599, 2], [1600, 2], [1601, 0], [1602, 2], [1603, 1], [1604, 7], [1605, 2], [1606, 5], [1607, 2], [1608, 0], [1609, 8], [1610, 7], [1611, 6], [1612, 5], [1613, 9], [1614, 3], [1615, 4], [1616, 0], [1617, 7], [1618, 3], [1619, 5], [1620, 6], [1621, 3], [1622, 1], [1623, 1], [1624, 9], [1625, 9], [1626, 9], [1627, 7], [1628, 8], [1629, 0], [1630, 6], [1631, 0], [1632, 3], [1633, 2], [1634, 7], [1635, 8], [1636, 6], [1637, 1], [1638, 9], [1639, 4], [1640, 7], [1641, 2], [1642, 4], [1643, 3], [1644, 9], [1645, 8], [1646, 6], [1647, 5], [1648, 9], [1649, 1], [1650, 2], [1651, 1], [1652, 0], [1653, 8], [1654, 0], [1655, 4], [1656, 5], [1657, 2], [1658, 2], [1659, 9], [1660, 2], [1661, 8], [1662, 8], [1663, 7], [1664, 1], [1665, 0], [1666, 8], [1667, 8], [1668, 9], [1669, 0], [1670, 0], [1671, 3], [1672, 6], [1673, 4], [1674, 1], [1675, 0], [1676, 7], [1677, 0], [1678, 8], [1679, 2], [1680, 2], [1681, 8], [1682, 9], [1683, 8], [1684, 7], [1685, 8], [1686, 3], [1687, 1], [1688, 4], [1689, 5], [1690, 0], [1691, 3], [1692, 8], [1693, 6], [1694, 0], [1695, 0], [1696, 8], [1697, 1], [1698, 3], [1699, 7], [1700, 4], [1701, 6], [1702, 8], [1703, 3], [1704, 7], [1705, 3], [1706, 0], [1707, 9], [1708, 4], [1709, 9], [1710, 6], [1711, 6], [1712, 9], [1713, 0], [1714, 4], [1715, 6], [1716, 5], [1717, 8], [1718, 9], [1719, 2], [1720, 0], [1721, 2], [1722, 1], [1723, 3], [1724, 3], [1725, 2], [1726, 1], [1727, 7], [1728, 3], [1729, 9], [1730, 7], [1731, 1], [1732, 5], [1733, 1], [1734, 3], [1735, 1], [1736, 8], [1737, 0], [1738, 2], [1739, 9], [1740, 1], [1741, 2], [1742, 7], [1743, 5], [1744, 4], [1745, 9], [1746, 0], [1747, 7], [1748, 8], [1749, 2], [1750, 1], [1751, 8], [1752, 4], [1753, 4], [1754, 8], [1755, 5], [1756, 0], [1757, 2], [1758, 8], [1759, 1], [1760, 5], [1761, 9], [1762, 6], [1763, 7], [1764, 0], [1765, 7], [1766, 6], [1767, 9], [1768, 5], [1769, 2], [1770, 1], [1771, 7], [1772, 5], [1773, 7], [1774, 3], [1775, 2], [1776, 2], [1777, 0], [1778, 3], [1779, 1], [1780, 6], [1781, 3], [1782, 7], [1783, 2], [1784, 1], [1785, 9], [1786, 6], [1787, 1], [1788, 9], [1789, 5], [1790, 6], [1791, 2], [1792, 8], [1793, 4], [1794, 7], [1795, 6], [1796, 0], [1797, 6], [1798, 2], [1799, 3], [1800, 3], [1801, 9], [1802, 5], [1803, 9], [1804, 0], [1805, 5], [1806, 6], [1807, 2], [1808, 6], [1809, 0], [1810, 7], [1811, 7], [1812, 6], [1813, 6], [1814, 1], [1815, 1], [1816, 7], [1817, 4], [1818, 4], [1819, 4], [1820, 3], [1821, 6], [1822, 8], [1823, 3], [1824, 7], [1825, 5], [1826, 3], [1827, 1], [1828, 5], [1829, 2], [1830, 2], [1831, 8], [1832, 6], [1833, 7], [1834, 5], [1835, 3], [1836, 7], [1837, 5], [1838, 1], [1839, 9], [1840, 0], [1841, 0], [1842, 7], [1843, 2], [1844, 6], [1845, 0], [1846, 1], [1847, 0], [1848, 0], [1849, 1], [1850, 0], [1851, 7], [1852, 6], [1853, 4], [1854, 6], [1855, 1], [1856, 4], [1857, 1], [1858, 2], [1859, 8], [1860, 0], [1861, 9], [1862, 0], [1863, 1], [1864, 7], [1865, 6], [1866, 4], [1867, 3], [1868, 3], [1869, 2], [1870, 9], [1871, 9], [1872, 8], [1873, 8], [1874, 0], [1875, 8], [1876, 0], [1877, 1], [1878, 3], [1879, 8], [1880, 8], [1881, 3], [1882, 1], [1883, 6], [1884, 1], [1885, 3], [1886, 9], [1887, 3], [1888, 0], [1889, 8], [1890, 8], [1891, 4], [1892, 4], [1893, 9], [1894, 8], [1895, 6], [1896, 2], [1897, 7], [1898, 2], [1899, 9], [1900, 5], [1901, 8], [1902, 1], [1903, 4], [1904, 6], [1905, 2], [1906, 9], [1907, 6], [1908, 7], [1909, 3], [1910, 1], [1911, 0], [1912, 9], [1913, 6], [1914, 7], [1915, 4], [1916, 8], [1917, 1], [1918, 9], [1919, 6], [1920, 3], [1921, 0], [1922, 6], [1923, 5], [1924, 0], [1925, 3], [1926, 2], [1927, 1], [1928, 0], [1929, 5], [1930, 8], [1931, 2], [1932, 4], [1933, 2], [1934, 6], [1935, 8], [1936, 1], [1937, 1], [1938, 5], [1939, 1], [1940, 0], [1941, 6], [1942, 0], [1943, 9], [1944, 3], [1945, 3], [1946, 8], [1947, 8], [1948, 6], [1949, 3], [1950, 2], [1951, 2], [1952, 7], [1953, 2], [1954, 9], [1955, 7], [1956, 5], [1957, 4], [1958, 2], [1959, 4], [1960, 6], [1961, 9], [1962, 9], [1963, 6], [1964, 3], [1965, 6], [1966, 8], [1967, 3], [1968, 5], [1969, 3], [1970, 1], [1971, 7], [1972, 2], [1973, 0], [1974, 8], [1975, 5], [1976, 4], [1977, 7], [1978, 9], [1979, 3], [1980, 8], [1981, 3], [1982, 3], [1983, 5], [1984, 1], [1985, 3], [1986, 7], [1987, 1], [1988, 1], [1989, 4], [1990, 1], [1991, 0], [1992, 1], [1993, 6], [1994, 5], [1995, 1], [1996, 5], [1997, 6], [1998, 0], [1999, 0], [2000, 3], [2001, 3], [2002, 8], [2003, 9], [2004, 1], [2005, 4], [2006, 1], [2007, 4], [2008, 0], [2009, 5], [2010, 1], [2011, 8], [2012, 2], [2013, 6], [2014, 0], [2015, 4], [2016, 2], [2017, 6], [2018, 0], [2019, 4], [2020, 2], [2021, 0], [2022, 1], [2023, 5], [2024, 6], [2025, 7], [2026, 0], [2027, 1], [2028, 2], [2029, 0], [2030, 7], [2031, 0], [2032, 5], [2033, 8], [2034, 6], [2035, 9], [2036, 0], [2037, 2], [2038, 6], [2039, 2], [2040, 1], [2041, 1], [2042, 5], [2043, 8], [2044, 8], [2045, 3], [2046, 3], [2047, 9], [2048, 3], [2049, 5], [2050, 2], [2051, 2], [2052, 8], [2053, 5], [2054, 8], [2055, 1], [2056, 0], [2057, 0], [2058, 0], [2059, 2], [2060, 0], [2061, 2], [2062, 3], [2063, 1], [2064, 3], [2065, 4], [2066, 5], [2067, 1], [2068, 8], [2069, 0], [2070, 1], [2071, 8], [2072, 8], [2073, 1], [2074, 2], [2075, 3], [2076, 4], [2077, 3], [2078, 2], [2079, 7], [2080, 5], [2081, 9], [2082, 6], [2083, 3], [2084, 9], [2085, 6], [2086, 1], [2087, 4], [2088, 1], [2089, 1], [2090, 1], [2091, 1], [2092, 8], [2093, 7], [2094, 1], [2095, 3], [2096, 6], [2097, 9], [2098, 4], [2099, 6], [2100, 3], [2101, 3], [2102, 9], [2103, 3], [2104, 6], [2105, 1], [2106, 4], [2107, 7], [2108, 6], [2109, 4], [2110, 3], [2111, 7], [2112, 9], [2113, 7], [2114, 1], [2115, 4], [2116, 0], [2117, 1], [2118, 2], [2119, 3], [2120, 3], [2121, 7], [2122, 6], [2123, 4], [2124, 6], [2125, 6], [2126, 8], [2127, 3], [2128, 2], [2129, 0], [2130, 1], [2131, 7], [2132, 8], [2133, 5], [2134, 0], [2135, 9], [2136, 0], [2137, 3], [2138, 9], [2139, 5], [2140, 6], [2141, 7], [2142, 0], [2143, 9], [2144, 1], [2145, 5], [2146, 4], [2147, 3], [2148, 5], [2149, 7], [2150, 2], [2151, 7], [2152, 0], [2153, 1], [2154, 6], [2155, 8], [2156, 6], [2157, 0], [2158, 8], [2159, 1], [2160, 7], [2161, 0], [2162, 3], [2163, 9], [2164, 1], [2165, 9], [2166, 0], [2167, 3], [2168, 6], [2169, 3], [2170, 4], [2171, 9], [2172, 0], [2173, 0], [2174, 7], [2175, 1], [2176, 5], [2177, 1], [2178, 8], [2179, 2], [2180, 8], [2181, 5], [2182, 8], [2183, 5], [2184, 2], [2185, 2], [2186, 2], [2187, 2], [2188, 4], [2189, 9], [2190, 5], [2191, 4], [2192, 3], [2193, 3], [2194, 2], [2195, 9], [2196, 7], [2197, 8], [2198, 8], [2199, 6], [2200, 4], [2201, 2], [2202, 5], [2203, 1], [2204, 4], [2205, 6], [2206, 1], [2207, 7], [2208, 2], [2209, 6], [2210, 5], [2211, 6], [2212, 0], [2213, 8], [2214, 3], [2215, 5], [2216, 5], [2217, 1], [2218, 0], [2219, 4], [2220, 4], [2221, 5], [2222, 0], [2223, 5], [2224, 0], [2225, 2], [2226, 2], [2227, 3], [2228, 4], [2229, 7], [2230, 5], [2231, 2], [2232, 7], [2233, 9], [2234, 1], [2235, 0], [2236, 3], [2237, 0], [2238, 7], [2239, 0], [2240, 0], [2241, 4], [2242, 2], [2243, 3], [2244, 4], [2245, 8], [2246, 7], [2247, 8], [2248, 2], [2249, 1], [2250, 4], [2251, 9], [2252, 4], [2253, 8], [2254, 5], [2255, 6], [2256, 2], [2257, 2], [2258, 0], [2259, 4], [2260, 1], [2261, 4], [2262, 0], [2263, 3], [2264, 7], [2265, 0], [2266, 7], [2267, 9], [2268, 8], [2269, 1], [2270, 1], [2271, 3], [2272, 6], [2273, 7], [2274, 3], [2275, 7], [2276, 3], [2277, 6], [2278, 1], [2279, 8], [2280, 9], [2281, 9], [2282, 2], [2283, 8], [2284, 9], [2285, 2], [2286, 1], [2287, 3], [2288, 1], [2289, 8], [2290, 8], [2291, 3], [2292, 2], [2293, 3], [2294, 9], [2295, 0], [2296, 1], [2297, 7], [2298, 5], [2299, 6], [2300, 0], [2301, 2], [2302, 7], [2303, 6], [2304, 5], [2305, 6], [2306, 4], [2307, 2], [2308, 3], [2309, 6], [2310, 7], [2311, 5], [2312, 0], [2313, 4], [2314, 6], [2315, 7], [2316, 7], [2317, 9], [2318, 2], [2319, 6], [2320, 3], [2321, 1], [2322, 8], [2323, 2], [2324, 9], [2325, 4], [2326, 3], [2327, 5], [2328, 8], [2329, 0], [2330, 6], [2331, 8], [2332, 9], [2333, 3], [2334, 9], [2335, 6], [2336, 4], [2337, 6], [2338, 0], [2339, 8], [2340, 0], [2341, 3], [2342, 7], [2343, 9], [2344, 7], [2345, 9], [2346, 2], [2347, 7], [2348, 1], [2349, 4], [2350, 1], [2351, 7], [2352, 0], [2353, 8], [2354, 6], [2355, 6], [2356, 3], [2357, 0], [2358, 8], [2359, 2], [2360, 5], [2361, 9], [2362, 8], [2363, 6], [2364, 0], [2365, 9], [2366, 8], [2367, 5], [2368, 5], [2369, 0], [2370, 8], [2371, 2], [2372, 1], [2373, 3], [2374, 1], [2375, 8], [2376, 1], [2377, 8], [2378, 2], [2379, 9], [2380, 9], [2381, 9], [2382, 0], [2383, 5], [2384, 4], [2385, 5], [2386, 4], [2387, 1], [2388, 8], [2389, 2], [2390, 9], [2391, 5], [2392, 0], [2393, 6], [2394, 7], [2395, 1], [2396, 4], [2397, 5], [2398, 8], [2399, 4], [2400, 8], [2401, 3], [2402, 7], [2403, 4], [2404, 7], [2405, 9], [2406, 8], [2407, 3], [2408, 7], [2409, 9], [2410, 6], [2411, 8], [2412, 0], [2413, 7], [2414, 1], [2415, 2], [2416, 8], [2417, 8], [2418, 9], [2419, 3], [2420, 1], [2421, 5], [2422, 0], [2423, 6], [2424, 6], [2425, 8], [2426, 7], [2427, 9], [2428, 6], [2429, 6], [2430, 6], [2431, 0], [2432, 9], [2433, 1], [2434, 1], [2435, 3], [2436, 7], [2437, 8], [2438, 1], [2439, 3], [2440, 7], [2441, 4], [2442, 0], [2443, 7], [2444, 7], [2445, 5], [2446, 9], [2447, 4], [2448, 0], [2449, 6], [2450, 6], [2451, 4], [2452, 5], [2453, 6], [2454, 8], [2455, 4], [2456, 8], [2457, 2], [2458, 5], [2459, 3], [2460, 1], [2461, 8], [2462, 7], [2463, 6], [2464, 9], [2465, 5], [2466, 0], [2467, 6], [2468, 8], [2469, 8], [2470, 2], [2471, 3], [2472, 9], [2473, 2], [2474, 1], [2475, 4], [2476, 4], [2477, 8], [2478, 1], [2479, 7], [2480, 3], [2481, 5], [2482, 2], [2483, 3], [2484, 2], [2485, 4], [2486, 8], [2487, 7], [2488, 2], [2489, 5], [2490, 1], [2491, 4], [2492, 2], [2493, 0], [2494, 1], [2495, 0], [2496, 0], [2497, 3], [2498, 9], [2499, 1], [2500, 0]]\n"
     ]
    }
   ],
   "source": [
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sub = pd.DataFrame(ans)\n",
    "sub = sub.rename(index=str, columns={0: \"ID\", 1: \"Class\"})\n",
    "sub.to_csv('submission3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0  1\n",
      "0        1  2\n",
      "1        2  9\n",
      "2        3  0\n",
      "3        4  4\n",
      "4        5  9\n",
      "5        6  5\n",
      "6        7  8\n",
      "7        8  5\n",
      "8        9  5\n",
      "9       10  3\n",
      "10      11  4\n",
      "11      12  9\n",
      "12      13  9\n",
      "13      14  6\n",
      "14      15  2\n",
      "15      16  9\n",
      "16      17  7\n",
      "17      18  4\n",
      "18      19  3\n",
      "19      20  1\n",
      "20      21  0\n",
      "21      22  1\n",
      "22      23  7\n",
      "23      24  2\n",
      "24      25  5\n",
      "25      26  0\n",
      "26      27  6\n",
      "27      28  8\n",
      "28      29  2\n",
      "29      30  1\n",
      "...    ... ..\n",
      "2470  2471  3\n",
      "2471  2472  9\n",
      "2472  2473  2\n",
      "2473  2474  1\n",
      "2474  2475  4\n",
      "2475  2476  4\n",
      "2476  2477  8\n",
      "2477  2478  1\n",
      "2478  2479  7\n",
      "2479  2480  3\n",
      "2480  2481  5\n",
      "2481  2482  2\n",
      "2482  2483  3\n",
      "2483  2484  2\n",
      "2484  2485  4\n",
      "2485  2486  8\n",
      "2486  2487  7\n",
      "2487  2488  2\n",
      "2488  2489  5\n",
      "2489  2490  1\n",
      "2490  2491  4\n",
      "2491  2492  2\n",
      "2492  2493  0\n",
      "2493  2494  1\n",
      "2494  2495  0\n",
      "2495  2496  0\n",
      "2496  2497  3\n",
      "2497  2498  9\n",
      "2498  2499  1\n",
      "2499  2500  0\n",
      "\n",
      "[2500 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
