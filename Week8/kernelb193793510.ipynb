{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('./input'):\n",
    "    for filename in filenames:\n",
    "        continue\n",
    "        #print(os.path.join(dirname, filename))\n",
    "import random \n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['daisy', '.ipynb_checkpoints', 'dandelion', 'rose', 'sunflower', 'tulip']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir('./input/coic2/flowers/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "IMG_SIZE=150\n",
    "FLOWER_DAISY_DIR='./input/coic2/flowers/daisy'\n",
    "FLOWER_SUNFLOWER_DIR='./input/coic2/flowers/sunflower'\n",
    "FLOWER_TULIP_DIR='./input/coic2/flowers/tulip'\n",
    "FLOWER_DANDI_DIR='./input/coic2/flowers/dandelion'\n",
    "FLOWER_ROSE_DIR='./input/coic2/flowers/rose'\n",
    "#flower_class_dir=['./input/coic2/flowers/daisy','./input/coic2/flowers/tulip','./input/coic2/flowers/sunflower',\n",
    "#                  './input/coic2/flowers/dandelion','./input/coic2/flowers/rose']\n",
    "def make_train_data(name,DIR,x,y):\n",
    "    for img in tqdm(os.listdir(DIR)):\n",
    "        path = os.path.join(DIR,img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        x.append(np.array(img))\n",
    "        y.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 725/725 [00:01<00:00, 460.95it/s]\n",
      "100%|██████████| 682/682 [00:01<00:00, 356.11it/s]\n",
      "100%|██████████| 934/934 [00:02<00:00, 341.92it/s]\n",
      "100%|██████████| 1010/1010 [00:04<00:00, 231.71it/s]\n",
      "100%|██████████| 735/735 [00:01<00:00, 511.38it/s]\n"
     ]
    }
   ],
   "source": [
    "make_train_data('Daisy',FLOWER_DAISY_DIR,x,y)\n",
    "make_train_data('Sunflower',FLOWER_SUNFLOWER_DIR,x,y)\n",
    "make_train_data('Tulip',FLOWER_TULIP_DIR,x,y)\n",
    "make_train_data('Dandelion',FLOWER_DANDI_DIR,x,y)\n",
    "make_train_data('Rose',FLOWER_ROSE_DIR,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4086 4086\n"
     ]
    }
   ],
   "source": [
    "print(len(x),len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax=plt.subplots(5,2)\n",
    "fig.set_size_inches(15,15)\n",
    "for i in range(5):\n",
    "    for j in range (2):\n",
    "        l=random.randint(0,len(y))\n",
    "        ax[i,j].imshow(x[l])\n",
    "        ax[i,j].set_title('Flower: '+y[l])\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "le=LabelEncoder()\n",
    "Y=le.fit_transform(y)\n",
    "print(Y)\n",
    "Y=to_categorical(Y,5)\n",
    "X=np.array(x)\n",
    "X=X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4086, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(np.random.seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # modelling starts using a CNN.\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Activation,Dropout\n",
    "from tensorflow.keras.optimizers import Adam,Adadelta\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',activation ='relu', input_shape = (150,150,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters =96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters = 96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(5, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#solve overfitting: https://ithelp.ithome.com.tw/articles/10203371\n",
    "#explain genator : https://zhuanlan.zhihu.com/p/30197320\n",
    "generator=ImageDataGenerator(samplewise_std_normalization=False,\n",
    "                   #zca_whitening=True, complex picture may take long time\n",
    "                   #zca_epsilon=1e-06,\n",
    "                   rotation_range=15,\n",
    "                   width_shift_range=0.1,\n",
    "                   height_shift_range=0.1,\n",
    "                   #shear_range=0.0, # shear image axis but fix the y axis\n",
    "                   zoom_range=0.1,\n",
    "                   channel_shift_range=0.0,\n",
    "                   horizontal_flip=True,\n",
    "                   vertical_flip=False,\n",
    "                   rescale=None,\n",
    "                   #fill_mode='wrap',may not suit to this problem\n",
    "                   dtype='float32')\n",
    "generator.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NoneType'> None\n"
     ]
    }
   ],
   "source": [
    "print(type(generator.fit(x_train)),generator.fit(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 37, 37, 96)        55392     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 18, 18, 96)        83040     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 96)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 9, 96)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 7776)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               3981824   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 4,143,749\n",
      "Trainable params: 4,143,749\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build(input_shape=[None, 150,150,3])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38\n",
      "102/102 [==============================] - 15s 144ms/step - loss: 1.4999 - accuracy: 0.2593 - val_loss: 1.2374 - val_accuracy: 0.4927\n",
      "Epoch 2/38\n",
      "102/102 [==============================] - 13s 132ms/step - loss: 1.1550 - accuracy: 0.4847 - val_loss: 1.0136 - val_accuracy: 0.5868\n",
      "Epoch 3/38\n",
      "102/102 [==============================] - 14s 133ms/step - loss: 1.0211 - accuracy: 0.5973 - val_loss: 1.0018 - val_accuracy: 0.5892\n",
      "Epoch 4/38\n",
      "102/102 [==============================] - 13s 127ms/step - loss: 0.9641 - accuracy: 0.6061 - val_loss: 0.9827 - val_accuracy: 0.6027\n",
      "Epoch 5/38\n",
      "102/102 [==============================] - 13s 131ms/step - loss: 0.8935 - accuracy: 0.6459 - val_loss: 0.8662 - val_accuracy: 0.6455\n",
      "Epoch 6/38\n",
      "102/102 [==============================] - 13s 129ms/step - loss: 0.8537 - accuracy: 0.6847 - val_loss: 0.9481 - val_accuracy: 0.6296\n",
      "Epoch 7/38\n",
      "102/102 [==============================] - 13s 129ms/step - loss: 0.8321 - accuracy: 0.6789 - val_loss: 0.8209 - val_accuracy: 0.6748\n",
      "Epoch 8/38\n",
      "102/102 [==============================] - 13s 127ms/step - loss: 0.7978 - accuracy: 0.6941 - val_loss: 0.8221 - val_accuracy: 0.6846\n",
      "Epoch 9/38\n",
      "102/102 [==============================] - 13s 127ms/step - loss: 0.7647 - accuracy: 0.7219 - val_loss: 0.7527 - val_accuracy: 0.7066\n",
      "Epoch 10/38\n",
      "102/102 [==============================] - 13s 128ms/step - loss: 0.7170 - accuracy: 0.7344 - val_loss: 0.7378 - val_accuracy: 0.7078\n",
      "Epoch 11/38\n",
      "102/102 [==============================] - 13s 127ms/step - loss: 0.6976 - accuracy: 0.7377 - val_loss: 0.7535 - val_accuracy: 0.6870\n",
      "Epoch 12/38\n",
      "102/102 [==============================] - 13s 128ms/step - loss: 0.7264 - accuracy: 0.7073 - val_loss: 0.7639 - val_accuracy: 0.6968\n",
      "Epoch 13/38\n",
      "102/102 [==============================] - 13s 128ms/step - loss: 0.6740 - accuracy: 0.7379 - val_loss: 0.7308 - val_accuracy: 0.7139\n",
      "Epoch 14/38\n",
      "102/102 [==============================] - 13s 128ms/step - loss: 0.6339 - accuracy: 0.7607 - val_loss: 0.7094 - val_accuracy: 0.7237\n",
      "Epoch 15/38\n",
      "102/102 [==============================] - 13s 128ms/step - loss: 0.6463 - accuracy: 0.7666 - val_loss: 0.7863 - val_accuracy: 0.7054\n",
      "Epoch 16/38\n",
      "102/102 [==============================] - 13s 127ms/step - loss: 0.6056 - accuracy: 0.7747 - val_loss: 0.6698 - val_accuracy: 0.7494\n",
      "Epoch 17/38\n",
      "102/102 [==============================] - 13s 127ms/step - loss: 0.5811 - accuracy: 0.7782 - val_loss: 0.7222 - val_accuracy: 0.7286\n",
      "Epoch 18/38\n",
      "102/102 [==============================] - 13s 129ms/step - loss: 0.5773 - accuracy: 0.7750 - val_loss: 0.6447 - val_accuracy: 0.7408\n",
      "Epoch 19/38\n",
      "102/102 [==============================] - 13s 129ms/step - loss: 0.5289 - accuracy: 0.8062 - val_loss: 0.6727 - val_accuracy: 0.7457\n",
      "Epoch 20/38\n",
      "102/102 [==============================] - 13s 127ms/step - loss: 0.5191 - accuracy: 0.8084 - val_loss: 0.6448 - val_accuracy: 0.7543\n",
      "Epoch 21/38\n",
      "102/102 [==============================] - 13s 129ms/step - loss: 0.5295 - accuracy: 0.7973 - val_loss: 0.6974 - val_accuracy: 0.7396\n",
      "Epoch 22/38\n",
      "102/102 [==============================] - 13s 126ms/step - loss: 0.5253 - accuracy: 0.8178 - val_loss: 0.7036 - val_accuracy: 0.7506\n",
      "Epoch 23/38\n",
      "102/102 [==============================] - 13s 129ms/step - loss: 0.4941 - accuracy: 0.8032 - val_loss: 0.6833 - val_accuracy: 0.7347\n",
      "Epoch 24/38\n",
      "102/102 [==============================] - 13s 129ms/step - loss: 0.4626 - accuracy: 0.8237 - val_loss: 0.6823 - val_accuracy: 0.7482\n",
      "Epoch 25/38\n",
      "102/102 [==============================] - 13s 126ms/step - loss: 0.4623 - accuracy: 0.8209 - val_loss: 0.6990 - val_accuracy: 0.7433\n",
      "Epoch 26/38\n",
      "102/102 [==============================] - 13s 129ms/step - loss: 0.4281 - accuracy: 0.8223 - val_loss: 0.6582 - val_accuracy: 0.7433\n",
      "Epoch 27/38\n",
      "102/102 [==============================] - 13s 128ms/step - loss: 0.4212 - accuracy: 0.8350 - val_loss: 0.6765 - val_accuracy: 0.7469\n",
      "Epoch 28/38\n",
      "102/102 [==============================] - 13s 127ms/step - loss: 0.3659 - accuracy: 0.8465 - val_loss: 0.6793 - val_accuracy: 0.7555\n",
      "Epoch 29/38\n",
      "102/102 [==============================] - 13s 129ms/step - loss: 0.3982 - accuracy: 0.8498 - val_loss: 0.7381 - val_accuracy: 0.7506\n",
      "Epoch 30/38\n",
      "102/102 [==============================] - 13s 126ms/step - loss: 0.3965 - accuracy: 0.8407 - val_loss: 0.6990 - val_accuracy: 0.7641\n",
      "Epoch 31/38\n",
      "102/102 [==============================] - 13s 128ms/step - loss: 0.3836 - accuracy: 0.8540 - val_loss: 0.6535 - val_accuracy: 0.7653\n",
      "Epoch 32/38\n",
      "102/102 [==============================] - 13s 128ms/step - loss: 0.3359 - accuracy: 0.8706 - val_loss: 0.6739 - val_accuracy: 0.7567\n",
      "Epoch 33/38\n",
      "102/102 [==============================] - 13s 126ms/step - loss: 0.3287 - accuracy: 0.8672 - val_loss: 0.7473 - val_accuracy: 0.7616\n",
      "Epoch 34/38\n",
      "102/102 [==============================] - 13s 126ms/step - loss: 0.3419 - accuracy: 0.8805 - val_loss: 0.6840 - val_accuracy: 0.7592\n",
      "Epoch 35/38\n",
      "102/102 [==============================] - 13s 130ms/step - loss: 0.2924 - accuracy: 0.8878 - val_loss: 0.7466 - val_accuracy: 0.7689\n",
      "Epoch 36/38\n",
      "102/102 [==============================] - 13s 130ms/step - loss: 0.3168 - accuracy: 0.8592 - val_loss: 0.6920 - val_accuracy: 0.7665\n",
      "Epoch 37/38\n",
      "101/102 [============================>.] - ETA: 0s - loss: 0.2986 - accuracy: 0.8973"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1add649b12a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m History = model.fit_generator(generator.flow(x_train,y_train, batch_size=batch_size),\n\u001b[1;32m      4\u001b[0m                               \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                               verbose = 1, steps_per_epoch=x_train.shape[0] // batch_size)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#History=model.fit(x_train, y_train,validation_data = (x_test,y_test), batch_size=32, epochs=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(generator)\u001b[0m\n\u001b[1;32m    361\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "epochs=38\n",
    "History = model.fit_generator(generator.flow(x_train,y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (x_test,y_test),\n",
    "                              verbose = 1, steps_per_epoch=x_train.shape[0] // batch_size)\n",
    "#History=model.fit(x_train, y_train,validation_data = (x_test,y_test), batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR='./input/coic2/unlabel-flowers'\n",
    "x_final_test=[]\n",
    "\"\"\"\n",
    "def make_test_data(TEST_DIR,x):\n",
    "    for img in tqdm(os.listdir(TEST_DIR)):\n",
    "        path = os.path.join(TEST_DIR,img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        x.append(np.array(img))\n",
    "make_test_data(TEST_DIR,x_final_test)\n",
    "\"\"\"\n",
    "for i in range(1,176):\n",
    "    path='./input/coic2/unlabel-flowers/{}.jpg'.format(i)\n",
    "    pic=cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "    pic = cv2.resize(pic, (IMG_SIZE,IMG_SIZE))\n",
    "    x_final_test.append(np.array(pic))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfig,ax=plt.subplots(5,2)\\nfig.set_size_inches(15,15)\\nfor i in range(5):\\n    for j in range (2):\\n        l=random.randint(0,len(y))\\n        ax[i,j].imshow(x_final_test[l])\\n\\nplt.tight_layout()\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "fig,ax=plt.subplots(5,2)\n",
    "fig.set_size_inches(15,15)\n",
    "for i in range(5):\n",
    "    for j in range (2):\n",
    "        l=random.randint(0,len(y))\n",
    "        ax[i,j].imshow(x_final_test[l])\n",
    "\n",
    "plt.tight_layout()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 150, 150, 3)\n",
      "<class 'numpy.ndarray'> (175, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "#print(x_final_test[0][0])\n",
    "print(np.array(x_final_test).shape)\n",
    "x_final_test=np.array(x_final_test).astype('float32')/255\n",
    "print(type(x_final_test),x_final_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_final_test.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=model.predict(x_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#daisy=1, dandelion=2, rose=3, sunflower=4, tulip=5.\n",
    "#print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=[]\n",
    "l=[]\n",
    "for i,pro in enumerate(tmp):\n",
    "    l=[i+1,pro.argmax()+1]\n",
    "    ans.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1] [2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(ans[0],ans[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub =  pd.DataFrame(ans)\n",
    "sub = sub.rename(index=str, columns={0: \"id\", 1: \"Class\"})\n",
    "sub.to_csv('submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
